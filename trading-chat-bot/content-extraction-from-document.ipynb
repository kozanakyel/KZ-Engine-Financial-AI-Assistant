{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-06-25T18:19:08.212928100Z",
     "start_time": "2023-06-25T18:19:07.443647400Z"
    }
   },
   "outputs": [
    {
     "ename": "ShellError",
     "evalue": "The command `pdf2txt.py data/ugur_akyel_20190808020_project_report.pdf` failed because the executable\n`pdf2txt.py` is not installed on your system. Please make\nsure the appropriate dependencies are installed before using\ntextract:\n\n    http://textract.readthedocs.org/en/latest/installation.html\n",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mFileNotFoundError\u001B[0m                         Traceback (most recent call last)",
      "File \u001B[0;32m~/.virtualenvs/llm-study-venv/lib/python3.8/site-packages/textract/parsers/utils.py:87\u001B[0m, in \u001B[0;36mShellParser.run\u001B[0;34m(self, args)\u001B[0m\n\u001B[1;32m     86\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[0;32m---> 87\u001B[0m     pipe \u001B[38;5;241m=\u001B[39m \u001B[43msubprocess\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mPopen\u001B[49m\u001B[43m(\u001B[49m\n\u001B[1;32m     88\u001B[0m \u001B[43m        \u001B[49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m     89\u001B[0m \u001B[43m        \u001B[49m\u001B[43mstdout\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43msubprocess\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mPIPE\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mstderr\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43msubprocess\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mPIPE\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m     90\u001B[0m \u001B[43m    \u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m     91\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m \u001B[38;5;167;01mOSError\u001B[39;00m \u001B[38;5;28;01mas\u001B[39;00m e:\n",
      "File \u001B[0;32m~/.pyenv/versions/3.8.1/lib/python3.8/subprocess.py:854\u001B[0m, in \u001B[0;36mPopen.__init__\u001B[0;34m(self, args, bufsize, executable, stdin, stdout, stderr, preexec_fn, close_fds, shell, cwd, env, universal_newlines, startupinfo, creationflags, restore_signals, start_new_session, pass_fds, encoding, errors, text)\u001B[0m\n\u001B[1;32m    851\u001B[0m             \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mstderr \u001B[38;5;241m=\u001B[39m io\u001B[38;5;241m.\u001B[39mTextIOWrapper(\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mstderr,\n\u001B[1;32m    852\u001B[0m                     encoding\u001B[38;5;241m=\u001B[39mencoding, errors\u001B[38;5;241m=\u001B[39merrors)\n\u001B[0;32m--> 854\u001B[0m     \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_execute_child\u001B[49m\u001B[43m(\u001B[49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mexecutable\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mpreexec_fn\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mclose_fds\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    855\u001B[0m \u001B[43m                        \u001B[49m\u001B[43mpass_fds\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mcwd\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43menv\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    856\u001B[0m \u001B[43m                        \u001B[49m\u001B[43mstartupinfo\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mcreationflags\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mshell\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    857\u001B[0m \u001B[43m                        \u001B[49m\u001B[43mp2cread\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mp2cwrite\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    858\u001B[0m \u001B[43m                        \u001B[49m\u001B[43mc2pread\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mc2pwrite\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    859\u001B[0m \u001B[43m                        \u001B[49m\u001B[43merrread\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43merrwrite\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    860\u001B[0m \u001B[43m                        \u001B[49m\u001B[43mrestore_signals\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mstart_new_session\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    861\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m:\n\u001B[1;32m    862\u001B[0m     \u001B[38;5;66;03m# Cleanup if the child failed starting.\u001B[39;00m\n",
      "File \u001B[0;32m~/.pyenv/versions/3.8.1/lib/python3.8/subprocess.py:1702\u001B[0m, in \u001B[0;36mPopen._execute_child\u001B[0;34m(self, args, executable, preexec_fn, close_fds, pass_fds, cwd, env, startupinfo, creationflags, shell, p2cread, p2cwrite, c2pread, c2pwrite, errread, errwrite, restore_signals, start_new_session)\u001B[0m\n\u001B[1;32m   1701\u001B[0m         err_msg \u001B[38;5;241m=\u001B[39m os\u001B[38;5;241m.\u001B[39mstrerror(errno_num)\n\u001B[0;32m-> 1702\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m child_exception_type(errno_num, err_msg, err_filename)\n\u001B[1;32m   1703\u001B[0m \u001B[38;5;28;01mraise\u001B[39;00m child_exception_type(err_msg)\n",
      "\u001B[0;31mFileNotFoundError\u001B[0m: [Errno 2] No such file or directory: 'pdf2txt.py'",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001B[0;31mShellError\u001B[0m                                Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[1], line 13\u001B[0m\n\u001B[1;32m     10\u001B[0m os\u001B[38;5;241m.\u001B[39menviron[\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mOPENAI_API_KEY\u001B[39m\u001B[38;5;124m'\u001B[39m] \u001B[38;5;241m=\u001B[39m openai_api_key\n\u001B[1;32m     12\u001B[0m \u001B[38;5;66;03m# Extract the raw text from each PDF using textract\u001B[39;00m\n\u001B[0;32m---> 13\u001B[0m text \u001B[38;5;241m=\u001B[39m \u001B[43mtextract\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mprocess\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[38;5;124;43mdata/ugur_akyel_20190808020_project_report.pdf\u001B[39;49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mmethod\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[38;5;124;43mpdfminer\u001B[39;49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[43m)\u001B[49m\u001B[38;5;241m.\u001B[39mdecode(\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mutf-8\u001B[39m\u001B[38;5;124m'\u001B[39m)\n\u001B[1;32m     14\u001B[0m clean_text \u001B[38;5;241m=\u001B[39m text\u001B[38;5;241m.\u001B[39mreplace(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m  \u001B[39m\u001B[38;5;124m\"\u001B[39m, \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m \u001B[39m\u001B[38;5;124m\"\u001B[39m)\u001B[38;5;241m.\u001B[39mreplace(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;130;01m\\n\u001B[39;00m\u001B[38;5;124m\"\u001B[39m, \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m; \u001B[39m\u001B[38;5;124m\"\u001B[39m)\u001B[38;5;241m.\u001B[39mreplace(\u001B[38;5;124m'\u001B[39m\u001B[38;5;124m;\u001B[39m\u001B[38;5;124m'\u001B[39m,\u001B[38;5;124m'\u001B[39m\u001B[38;5;124m \u001B[39m\u001B[38;5;124m'\u001B[39m)\n",
      "File \u001B[0;32m~/.virtualenvs/llm-study-venv/lib/python3.8/site-packages/textract/parsers/__init__.py:79\u001B[0m, in \u001B[0;36mprocess\u001B[0;34m(filename, input_encoding, output_encoding, extension, **kwargs)\u001B[0m\n\u001B[1;32m     76\u001B[0m \u001B[38;5;66;03m# do the extraction\u001B[39;00m\n\u001B[1;32m     78\u001B[0m parser \u001B[38;5;241m=\u001B[39m filetype_module\u001B[38;5;241m.\u001B[39mParser()\n\u001B[0;32m---> 79\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mparser\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mprocess\u001B[49m\u001B[43m(\u001B[49m\u001B[43mfilename\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43minput_encoding\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43moutput_encoding\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/.virtualenvs/llm-study-venv/lib/python3.8/site-packages/textract/parsers/utils.py:46\u001B[0m, in \u001B[0;36mBaseParser.process\u001B[0;34m(self, filename, input_encoding, output_encoding, **kwargs)\u001B[0m\n\u001B[1;32m     36\u001B[0m \u001B[38;5;250m\u001B[39m\u001B[38;5;124;03m\"\"\"Process ``filename`` and encode byte-string with ``encoding``. This\u001B[39;00m\n\u001B[1;32m     37\u001B[0m \u001B[38;5;124;03mmethod is called by :func:`textract.parsers.process` and wraps\u001B[39;00m\n\u001B[1;32m     38\u001B[0m \u001B[38;5;124;03mthe :meth:`.BaseParser.extract` method in `a delicious unicode\u001B[39;00m\n\u001B[1;32m     39\u001B[0m \u001B[38;5;124;03msandwich <http://nedbatchelder.com/text/unipain.html>`_.\u001B[39;00m\n\u001B[1;32m     40\u001B[0m \n\u001B[1;32m     41\u001B[0m \u001B[38;5;124;03m\"\"\"\u001B[39;00m\n\u001B[1;32m     42\u001B[0m \u001B[38;5;66;03m# make a \"unicode sandwich\" to handle dealing with unknown\u001B[39;00m\n\u001B[1;32m     43\u001B[0m \u001B[38;5;66;03m# input byte strings and converting them to a predictable\u001B[39;00m\n\u001B[1;32m     44\u001B[0m \u001B[38;5;66;03m# output encoding\u001B[39;00m\n\u001B[1;32m     45\u001B[0m \u001B[38;5;66;03m# http://nedbatchelder.com/text/unipain/unipain.html#35\u001B[39;00m\n\u001B[0;32m---> 46\u001B[0m byte_string \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mextract\u001B[49m\u001B[43m(\u001B[49m\u001B[43mfilename\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m     47\u001B[0m unicode_string \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mdecode(byte_string, input_encoding)\n\u001B[1;32m     48\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mencode(unicode_string, output_encoding)\n",
      "File \u001B[0;32m~/.virtualenvs/llm-study-venv/lib/python3.8/site-packages/textract/parsers/pdf_parser.py:32\u001B[0m, in \u001B[0;36mParser.extract\u001B[0;34m(self, filename, method, **kwargs)\u001B[0m\n\u001B[1;32m     29\u001B[0m             \u001B[38;5;28;01mraise\u001B[39;00m ex\n\u001B[1;32m     31\u001B[0m \u001B[38;5;28;01melif\u001B[39;00m method \u001B[38;5;241m==\u001B[39m \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mpdfminer\u001B[39m\u001B[38;5;124m'\u001B[39m:\n\u001B[0;32m---> 32\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mextract_pdfminer\u001B[49m\u001B[43m(\u001B[49m\u001B[43mfilename\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m     33\u001B[0m \u001B[38;5;28;01melif\u001B[39;00m method \u001B[38;5;241m==\u001B[39m \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mtesseract\u001B[39m\u001B[38;5;124m'\u001B[39m:\n\u001B[1;32m     34\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mextract_tesseract(filename, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n",
      "File \u001B[0;32m~/.virtualenvs/llm-study-venv/lib/python3.8/site-packages/textract/parsers/pdf_parser.py:54\u001B[0m, in \u001B[0;36mParser.extract_pdfminer\u001B[0;34m(self, filename, **kwargs)\u001B[0m\n\u001B[1;32m     52\u001B[0m pdf2txt_path \u001B[38;5;241m=\u001B[39m find_executable(\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mpdf2txt.py\u001B[39m\u001B[38;5;124m'\u001B[39m)\n\u001B[1;32m     53\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[0;32m---> 54\u001B[0m     stdout, _ \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mrun\u001B[49m\u001B[43m(\u001B[49m\u001B[43m[\u001B[49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[38;5;124;43mpdf2txt.py\u001B[39;49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mfilename\u001B[49m\u001B[43m]\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m     55\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m \u001B[38;5;167;01mOSError\u001B[39;00m:\n\u001B[1;32m     56\u001B[0m     \u001B[38;5;28;01mtry\u001B[39;00m:\n",
      "File \u001B[0;32m~/.virtualenvs/llm-study-venv/lib/python3.8/site-packages/textract/parsers/utils.py:95\u001B[0m, in \u001B[0;36mShellParser.run\u001B[0;34m(self, args)\u001B[0m\n\u001B[1;32m     91\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m \u001B[38;5;167;01mOSError\u001B[39;00m \u001B[38;5;28;01mas\u001B[39;00m e:\n\u001B[1;32m     92\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m e\u001B[38;5;241m.\u001B[39merrno \u001B[38;5;241m==\u001B[39m errno\u001B[38;5;241m.\u001B[39mENOENT:\n\u001B[1;32m     93\u001B[0m         \u001B[38;5;66;03m# File not found.\u001B[39;00m\n\u001B[1;32m     94\u001B[0m         \u001B[38;5;66;03m# This is equivalent to getting exitcode 127 from sh\u001B[39;00m\n\u001B[0;32m---> 95\u001B[0m         \u001B[38;5;28;01mraise\u001B[39;00m exceptions\u001B[38;5;241m.\u001B[39mShellError(\n\u001B[1;32m     96\u001B[0m             \u001B[38;5;124m'\u001B[39m\u001B[38;5;124m \u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;241m.\u001B[39mjoin(args), \u001B[38;5;241m127\u001B[39m, \u001B[38;5;124m'\u001B[39m\u001B[38;5;124m'\u001B[39m, \u001B[38;5;124m'\u001B[39m\u001B[38;5;124m'\u001B[39m,\n\u001B[1;32m     97\u001B[0m         )\n\u001B[1;32m     98\u001B[0m     \u001B[38;5;28;01melse\u001B[39;00m: \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;66;03m#Reraise the last exception unmodified\u001B[39;00m\n\u001B[1;32m    100\u001B[0m \u001B[38;5;66;03m# pipe.wait() ends up hanging on large files. using\u001B[39;00m\n\u001B[1;32m    101\u001B[0m \u001B[38;5;66;03m# pipe.communicate appears to avoid this issue\u001B[39;00m\n",
      "\u001B[0;31mShellError\u001B[0m: The command `pdf2txt.py data/ugur_akyel_20190808020_project_report.pdf` failed because the executable\n`pdf2txt.py` is not installed on your system. Please make\nsure the appropriate dependencies are installed before using\ntextract:\n\n    http://textract.readthedocs.org/en/latest/installation.html\n"
     ]
    }
   ],
   "source": [
    "import textract\n",
    "import openai\n",
    "import tiktoken\n",
    "from dotenv import load_dotenv\n",
    "import os\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "openai_api_key = os.getenv('T_OPENAI_API_KEY')\n",
    "os.environ['OPENAI_API_KEY'] = openai_api_key\n",
    "\n",
    "# Extract the raw text from each PDF using textract\n",
    "text = textract.process('data/ugur_akyel_20190808020_project_report.pdf', method='pdfminer').decode('utf-8')\n",
    "clean_text = text.replace(\"  \", \" \").replace(\"\\n\", \"; \").replace(';',' ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extract key pieces of information from this regulation document.\n",
      "    If a particular piece of information is not present, output \"Not specified\".\n",
      "    When you extract a key piece of information, include the closest page number.\n",
      "    Use the following format:\n",
      "0. Who is the author\n",
      "1. What is the amount of the \"Power Unit Cost Cap\" in USD, GBP and EUR\n",
      "2. What is the value of External Manufacturing Costs in USD\n",
      "3. What is the Capital Expenditure Limit in USD\n",
      "\n",
      "Document: \"\"\"<document>\"\"\"\n",
      "\n",
      "0. Who is the author: Tom Anderson (Page 1)\n",
      "1.\n"
     ]
    }
   ],
   "source": [
    "# Example prompt - \n",
    "document = '<document>'\n",
    "template_prompt=f'''Extract key pieces of information from this regulation document.\n",
    "    If a particular piece of information is not present, output \\\"Not specified\\\".\n",
    "    When you extract a key piece of information, include the closest page number.\n",
    "    Use the following format:\\n0. Who is the author\\n1. What is the amount of the \"Power Unit Cost Cap\" in USD, GBP and EUR\\n2. What is the value of External Manufacturing Costs in USD\\n3. What is the Capital Expenditure Limit in USD\\n\\nDocument: \\\"\\\"\\\"{document}\\\"\\\"\\\"\\n\\n0. Who is the author: Tom Anderson (Page 1)\\n1.'''\n",
    "print(template_prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split a text into smaller chunks of size n, preferably ending at the end of a sentence\n",
    "def create_chunks(text, n, tokenizer):\n",
    "    tokens = tokenizer.encode(text)\n",
    "    \"\"\"Yield successive n-sized chunks from text.\"\"\"\n",
    "    i = 0\n",
    "    while i < len(tokens):\n",
    "        # Find the nearest end of sentence within a range of 0.5 * n and 1.5 * n tokens\n",
    "        j = min(i + int(1.5 * n), len(tokens))\n",
    "        while j > i + int(0.5 * n):\n",
    "            # Decode the tokens and check for full stop or newline\n",
    "            chunk = tokenizer.decode(tokens[i:j])\n",
    "            if chunk.endswith(\".\") or chunk.endswith(\"\\n\"):\n",
    "                break\n",
    "            j -= 1\n",
    "        # If no end of sentence found, use n tokens as the chunk size\n",
    "        if j == i + int(0.5 * n):\n",
    "            j = min(i + n, len(tokens))\n",
    "        yield tokens[i:j]\n",
    "        i = j\n",
    "\n",
    "def extract_chunk(document,template_prompt):\n",
    "    \n",
    "    prompt=template_prompt.replace('<document>',document)\n",
    "    openai.api_key = openai_api_key\n",
    "\n",
    "    response = openai.Completion.create(\n",
    "        model='text-davinci-003', \n",
    "        prompt=prompt,\n",
    "        temperature=0,\n",
    "        max_tokens=1500,\n",
    "        top_p=1,\n",
    "        frequency_penalty=0,\n",
    "        presence_penalty=0\n",
    "    )\n",
    "    return \"1.\" + response['choices'][0]['text']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialise tokenizer\n",
    "tokenizer = tiktoken.get_encoding(\"cl100k_base\")\n",
    "\n",
    "results = []\n",
    "    \n",
    "chunks = create_chunks(clean_text,1000,tokenizer)\n",
    "text_chunks = [tokenizer.decode(chunk) for chunk in chunks]\n",
    "\n",
    "for chunk in text_chunks:\n",
    "    results.append(extract_chunk(chunk,template_prompt))\n",
    "    #print(chunk)\n",
    "    #print(results[-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['3. What is the Capital Expenditure Limit in USD: $1,000,000 (Page 32)']"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "groups = [r.split('\\n') for r in results]\n",
    "\n",
    "# zip the groups together\n",
    "zipped = list(zip(*groups))\n",
    "zipped = [x for y in zipped for x in y if \"Not specified\" not in x and \"__\" not in x]\n",
    "zipped"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sorulari ve ozellikleri specific olarak belirlemek gerekiyor\n",
    "entity extraction icin baska yontemler denemek daha mantikli\n",
    "Bu iyi bir yontem degil...."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extract key pieces of information from this regulation document.\n",
      "If a particular piece of information is not present, output \"Not specified\".\n",
      "When you extract a key piece of information, include the closest page number.\n",
      "Use the following format:\n",
      "0. Who is the author\n",
      "1. How is a Minor Overspend Breach calculated\n",
      "2. How is a Major Overspend Breach calculated\n",
      "3. Which years do these financial regulations apply to\n",
      "\n",
      "Document: \"\"\"<document>\"\"\"\n",
      "\n",
      "0. Who is the author: Tom Anderson (Page 1)\n",
      "1.\n"
     ]
    }
   ],
   "source": [
    "# Example prompt - \n",
    "template_prompt=f'''Extract key pieces of information from this regulation document.\n",
    "    If a particular piece of information is not present, output \\\"Not specified\\\".\n",
    "    When you extract a key piece of information, include the closest page number.\n",
    "    Use the following format:\\n0. Who is the author\\n1. How is a Minor Overspend Breach calculated\\n2. How is a Major Overspend Breach calculated\\n3. Which years do these financial regulations apply to\\n\\nDocument: \\\"\\\"\\\"{document}\\\"\\\"\\\"\\n\\n0. Who is the author: Tom Anderson (Page 1)\\n1.'''\n",
    "print(template_prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['3. Which years do these financial regulations apply to: 2020-2021 (Page 1)']"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results = []\n",
    "\n",
    "for chunk in text_chunks:\n",
    "    results.append(extract_chunk(chunk,template_prompt))\n",
    "    \n",
    "groups = [r.split('\\n') for r in results]\n",
    "\n",
    "# zip the groups together\n",
    "zipped = list(zip(*groups))\n",
    "zipped = [x for y in zipped for x in y if \"Not specified\" not in x and \"__\" not in x]\n",
    "zipped"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "llm-study-venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.1"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
