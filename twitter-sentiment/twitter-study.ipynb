{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dotenv import load_dotenv\n",
    "import os\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "twitter_bearer_token = os.getenv('TW_BEARER_TOKEN')\n",
    "\n",
    "from langchain.document_loaders import TwitterTweetLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_users_twitter(file: str) -> list:\n",
    "    with open(file, 'r') as f:\n",
    "        usernames = f.read().splitlines()\n",
    "    return usernames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "loader = TwitterTweetLoader.from_bearer_token(\n",
    "    oauth2_bearer_token=twitter_bearer_token,\n",
    "    twitter_users=get_users_twitter('/mnt/c/Users/kozan/Desktop/Sen_Des_Proj/GPT-4-KZEngine-Signal-Interpretation/twitter-sentiment/list_users_twitter.txt'),\n",
    "    number_tweets=20000,  # Default value is 100\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1966"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "contents = []\n",
    "documents = loader.load()\n",
    "for doc in documents:\n",
    "    contents.append(doc.dict())\n",
    "len(contents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.DataFrame(contents)\n",
    "\n",
    "df['created_at'] = pd.to_datetime(df['metadata'].apply(lambda x: x['created_at']), format='%a %b %d %H:%M:%S %z %Y')\n",
    "df['screen_name'] = df['metadata'].apply(lambda x: x['user_info']['screen_name'])\n",
    "df = df[['screen_name', 'page_content', 'created_at']]\n",
    "df = df.rename(columns={'page_content': 'text', 'screen_name': 'username'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cleaning_tweet_data( df: pd.DataFrame()):\n",
    "        import re\n",
    "        df_tweets = df.copy()\n",
    "        if 'Unnamed: 0' in df_tweets.columns:\n",
    "            df_tweets.drop(columns=['Unnamed: 0'], axis=1, inplace=True)\n",
    "        if 'source' in df_tweets.columns:\n",
    "            df_tweets.drop(columns=['source', 'name', 'location', 'verified', 'description'], axis=1, inplace=True)\n",
    "            \n",
    "\n",
    "        df_tweets = df_tweets.apply(lambda x: x.astype(str).str.lower()).drop_duplicates(subset=['text', 'username'],\n",
    "                                                                                         keep='first')\n",
    "        \n",
    "        df_tweets['text'] = df_tweets['text'].apply(lambda x: re.split('https:\\/\\/.*', str(x))[0])\n",
    "        df_tweets['text'] = df_tweets['text'].str.lower()\n",
    "        df_tweets['text'] = df_tweets['text'].str.replace(\"@[a-z0-9A-Z]+\", \"\", regex=True)\n",
    "        df_tweets['text'] = df_tweets['text'].str.replace(\"#[a-z0-9A-Z]+\", \"\", regex=True)\n",
    "\n",
    "        blanks = []  # start with an empty list\n",
    "        for i, created_at, text, *username in df_tweets.itertuples():\n",
    "            if type(text) == str:\n",
    "                if text.isspace():\n",
    "                    blanks.append(i)\n",
    "        df_tweets.drop(blanks, inplace=True)\n",
    "        # df_tweets['text'] = df_tweets['text'].str.replace(r\"http\\S+\", \"\")\n",
    "        # df_tweets['text'] = df_tweets['text'].str.replace(r\"www.\\S+\", \"\")\n",
    "        # df_tweets['text'] = df_tweets['text'].str.replace('[()!?]', ' ')\n",
    "        # df_tweets['text'] = df_tweets['text'].str.replace('\\[.*?\\]',' ')\n",
    "        # df_tweets['text'] = df_tweets['text'].str.replace(\"[^a-z0-9]\",\" \")\n",
    "\n",
    "\n",
    "        df_tweets.dropna(inplace=True)\n",
    "\n",
    "\n",
    "        return df_tweets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 1966 entries, 0 to 1965\n",
      "Data columns (total 3 columns):\n",
      " #   Column      Non-Null Count  Dtype              \n",
      "---  ------      --------------  -----              \n",
      " 0   username    1966 non-null   object             \n",
      " 1   text        1966 non-null   object             \n",
      " 2   created_at  1966 non-null   datetime64[ns, UTC]\n",
      "dtypes: datetime64[ns, UTC](1), object(2)\n",
      "memory usage: 46.2+ KB\n"
     ]
    }
   ],
   "source": [
    "df['username'] = df['username'].astype(str)\n",
    "df['text'] = df['text'].astype(str)\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = cleaning_tweet_data(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocessing_tweet_datetime(df: pd.DataFrame()) -> pd.DataFrame():\n",
    "        \"\"\"\n",
    "        For adding datetime groups Date, Hour, Minute to existing Dataframe.\n",
    "            It uses to copy of existing Dataframe\n",
    "        Args:\n",
    "            self (tsa) \n",
    "            df (DataFrame)\n",
    "\n",
    "        Returns:\n",
    "            DataFrame\n",
    "        \"\"\"\n",
    "        df_temp = df.copy()\n",
    "        # Fixed for some blank tweets: 'tweets'. Interesting api result delete below with function\n",
    "        df_temp.drop(df_temp[df_temp.created_at == 'twitter'].index, inplace=True)\n",
    "        df_temp.created_at = pd.to_datetime(df_temp.created_at)\n",
    "        df_temp['Date'] = df_temp.created_at.apply(lambda x: x.date())\n",
    "        df_temp['hour'] = df_temp.created_at.apply(lambda x: x.hour)\n",
    "        df_temp['minute'] = df_temp.created_at.apply(lambda x: x.minute)\n",
    "        return df_temp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>username</th>\n",
       "      <th>text</th>\n",
       "      <th>created_at</th>\n",
       "      <th>Date</th>\n",
       "      <th>hour</th>\n",
       "      <th>minute</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>cryptocapo_</td>\n",
       "      <td>after hours and hours of deep analysis and re...</td>\n",
       "      <td>2023-04-11 12:27:50+00:00</td>\n",
       "      <td>2023-04-11</td>\n",
       "      <td>12</td>\n",
       "      <td>27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>cryptocapo_</td>\n",
       "      <td>rt _: some thoughts.\\n\\ni'll continue to ignor...</td>\n",
       "      <td>2023-04-11 12:06:35+00:00</td>\n",
       "      <td>2023-04-11</td>\n",
       "      <td>12</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>cryptocapo_</td>\n",
       "      <td>_mc  i've repeated many times that i'm short o...</td>\n",
       "      <td>2023-04-11 11:50:45+00:00</td>\n",
       "      <td>2023-04-11</td>\n",
       "      <td>11</td>\n",
       "      <td>50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>cryptocapo_</td>\n",
       "      <td>the joke would at least be funny if i shorted...</td>\n",
       "      <td>2023-04-11 11:46:53+00:00</td>\n",
       "      <td>2023-04-11</td>\n",
       "      <td>11</td>\n",
       "      <td>46</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>cryptocapo_</td>\n",
       "      <td>everything is based on probabilities. the mor...</td>\n",
       "      <td>2023-04-11 08:19:40+00:00</td>\n",
       "      <td>2023-04-11</td>\n",
       "      <td>8</td>\n",
       "      <td>19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1961</th>\n",
       "      <td>elonmusk</td>\n",
       "      <td>ad-free version if you subscribe to zuby!</td>\n",
       "      <td>2023-06-17 19:14:41+00:00</td>\n",
       "      <td>2023-06-17</td>\n",
       "      <td>19</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1962</th>\n",
       "      <td>elonmusk</td>\n",
       "      <td>rt : real talk with zuby podcast ep. 263 -  \\n...</td>\n",
       "      <td>2023-06-17 19:12:20+00:00</td>\n",
       "      <td>2023-06-17</td>\n",
       "      <td>19</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1963</th>\n",
       "      <td>elonmusk</td>\n",
       "      <td>this is very concerning</td>\n",
       "      <td>2023-06-17 19:10:29+00:00</td>\n",
       "      <td>2023-06-17</td>\n",
       "      <td>19</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1964</th>\n",
       "      <td>elonmusk</td>\n",
       "      <td>不不 that would definitely work for falling asl...</td>\n",
       "      <td>2023-06-17 18:36:18+00:00</td>\n",
       "      <td>2023-06-17</td>\n",
       "      <td>18</td>\n",
       "      <td>36</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1965</th>\n",
       "      <td>elonmusk</td>\n",
       "      <td>true</td>\n",
       "      <td>2023-06-17 18:29:30+00:00</td>\n",
       "      <td>2023-06-17</td>\n",
       "      <td>18</td>\n",
       "      <td>29</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1896 rows  6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         username                                               text  \\\n",
       "0     cryptocapo_   after hours and hours of deep analysis and re...   \n",
       "1     cryptocapo_  rt _: some thoughts.\\n\\ni'll continue to ignor...   \n",
       "2     cryptocapo_  _mc  i've repeated many times that i'm short o...   \n",
       "3     cryptocapo_   the joke would at least be funny if i shorted...   \n",
       "4     cryptocapo_   everything is based on probabilities. the mor...   \n",
       "...           ...                                                ...   \n",
       "1961     elonmusk          ad-free version if you subscribe to zuby!   \n",
       "1962     elonmusk  rt : real talk with zuby podcast ep. 263 -  \\n...   \n",
       "1963     elonmusk                            this is very concerning   \n",
       "1964     elonmusk   不不 that would definitely work for falling asl...   \n",
       "1965     elonmusk                                               true   \n",
       "\n",
       "                    created_at        Date  hour  minute  \n",
       "0    2023-04-11 12:27:50+00:00  2023-04-11    12      27  \n",
       "1    2023-04-11 12:06:35+00:00  2023-04-11    12       6  \n",
       "2    2023-04-11 11:50:45+00:00  2023-04-11    11      50  \n",
       "3    2023-04-11 11:46:53+00:00  2023-04-11    11      46  \n",
       "4    2023-04-11 08:19:40+00:00  2023-04-11     8      19  \n",
       "...                        ...         ...   ...     ...  \n",
       "1961 2023-06-17 19:14:41+00:00  2023-06-17    19      14  \n",
       "1962 2023-06-17 19:12:20+00:00  2023-06-17    19      12  \n",
       "1963 2023-06-17 19:10:29+00:00  2023-06-17    19      10  \n",
       "1964 2023-06-17 18:36:18+00:00  2023-06-17    18      36  \n",
       "1965 2023-06-17 18:29:30+00:00  2023-06-17    18      29  \n",
       "\n",
       "[1896 rows x 6 columns]"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = preprocessing_tweet_datetime(df)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "llm-study-venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.1"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
