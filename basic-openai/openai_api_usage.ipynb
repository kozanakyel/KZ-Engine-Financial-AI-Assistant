{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#openai initiliazer\n",
    "import openai\n",
    "from dotenv import load_dotenv\n",
    "import os\n",
    "import json\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "openai_api_key = os.getenv('OPENAI_API_KEY')"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "openai tools fine_tunes.prepare_data -f <LOCAL_FILE>\n",
    "openai api fine_tunes.create -t <TRAIN_FILE_ID_OR_PATH> -m <BASE_MODEL>\n",
    "openai api fine_tunes.follow -i <YOUR_FINE_TUNE_JOB_ID>\n",
    "openai api fine_tunes.list\n",
    "\n",
    "openai api fine_tunes.get -i <YOUR_FINE_TUNE_JOB_ID>\n",
    "\n",
    "openai api fine_tunes.cancel -i <YOUR_FINE_TUNE_JOB_ID>\n",
    "openai api completions.create -m <FINE_TUNED_MODEL> -p <YOUR_PROMPT>"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Each prompt should end with a fixed separator to inform the model when the prompt ends and the completion begins. A simple separator which generally works well is \\n\\n###\\n\\n. The separator should not appear elsewhere in any prompt.\n",
    "\n",
    "Each completion should start with a whitespace due to our tokenization, which tokenizes most words with a preceding whitespace.\n",
    "\n",
    "Each completion should end with a fixed stop sequence to inform the model when the completion ends. A stop sequence could be \\n, ###, or any other token that does not appear in any completion.\n",
    "\n",
    "For inference, you should format your prompts in the same way as you did when creating the training dataset, including the same separator. Also specify the same stop sequence to properly truncate the completion."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# jsonl file sended to openi for Fine-Tuned purposes\n",
    "openai.api_key = openai_api_key\n",
    "response_file_post = openai.File.create(\n",
    "  file=open(\"datatset_prepared.jsonl\", \"rb\"),\n",
    "  purpose='fine-tune'\n",
    ")\n",
    "response_file_post"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fine tuned and created model from file id\n",
    "openai.FineTune.create(training_file=\"file-rNx4Zl0bNp1c6Na0ALCzoVH2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# See all fine-tuned model list and status\n",
    "openai.FineTune.list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get response from new prompt\n",
    "fine_tuned_model_id = \"ft-kAhHsmceYiFD3CKTBJZgVMyi\"\n",
    "prompt = json.dumps(dt.to_json())\n",
    "\n",
    "response = openai.Completion.create(\n",
    "    model=fine_tuned_model_id,\n",
    "    prompt=prompt,\n",
    "    max_tokens=300\n",
    ")\n",
    "\n",
    "output_text = response.choices[0].text\n",
    "print(output_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get fine-tune id information\n",
    "fine_tune_id = \"ft-mhzCaPZwpXrfH3x1GRxzucB4\"\n",
    "\n",
    "# Use the OpenAI API to retrieve information about the fine-tuning task\n",
    "response = openai.FineTune.retrieve(fine_tune_id)\n",
    "\n",
    "# Print the JSON response\n",
    "print(json.dumps(response, indent=2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# delete fine-tuned models\n",
    "openai.Model.delete(\"ft-kAhHsmceYiFD3CKTBJZgVMyi\")"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
